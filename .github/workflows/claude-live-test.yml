name: Claude Live Testing

# AI-powered exploratory testing with Playwright MCP
# 
# Trigger 1: Add 'claude-test' label to PR → deploys to kind cluster
# Trigger 2: Manual workflow_dispatch → tests existing cluster

on:
  pull_request_target:
    types: [labeled]
    branches: [ main, master ]
  
  workflow_dispatch:
    inputs:
      base_url:
        description: 'Frontend URL (e.g., https://ambient-code.apps.cluster.com)'
        required: true
        type: string
      test_token:
        description: 'Auth token (run: oc whoami -t)'
        required: true
        type: string
      test_prompt:
        description: 'What to test (optional)'
        required: false
        type: string
        default: 'Perform comprehensive exploratory testing of the application'

permissions:
  contents: write
  pull-requests: write
  issues: write

concurrency:
  group: claude-test-${{ github.event.pull_request.number || github.run_id }}
  cancel-in-progress: true

jobs:
  # Determine mode and configuration
  setup:
    runs-on: ubuntu-latest
    outputs:
      mode: ${{ steps.detect.outputs.mode }}
      should-run: ${{ steps.detect.outputs.should-run }}
      base-url: ${{ steps.detect.outputs.base-url }}
      test-token: ${{ steps.detect.outputs.test-token }}
      test-prompt: ${{ steps.detect.outputs.test-prompt }}
    steps:
      - name: Detect trigger mode
        id: detect
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "mode=manual" >> $GITHUB_OUTPUT
            echo "should-run=true" >> $GITHUB_OUTPUT
            echo "base-url=${{ inputs.base_url }}" >> $GITHUB_OUTPUT
            echo "test-token=${{ inputs.test_token }}" >> $GITHUB_OUTPUT
            echo "test-prompt=${{ inputs.test_prompt }}" >> $GITHUB_OUTPUT
            echo "✅ Manual trigger - testing existing cluster at ${{ inputs.base_url }}"
          elif [ "${{ github.event.label.name }}" = "claude-test" ]; then
            echo "mode=pr" >> $GITHUB_OUTPUT
            echo "should-run=true" >> $GITHUB_OUTPUT
            echo "base-url=http://localhost" >> $GITHUB_OUTPUT
            echo "test-token=FROM_KIND" >> $GITHUB_OUTPUT
            echo "test-prompt=Test the PR changes" >> $GITHUB_OUTPUT
            echo "✅ PR label trigger - will deploy to kind"
          else
            echo "mode=skip" >> $GITHUB_OUTPUT
            echo "should-run=false" >> $GITHUB_OUTPUT
            echo "⏭️  Wrong label - skipping"
          fi

  # Deploy to kind (only for PR trigger)
  deploy-to-kind:
    name: Deploy PR to Kind
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.mode == 'pr'
    timeout-minutes: 20
    outputs:
      test-token: ${{ steps.token.outputs.token }}

    steps:
    - name: Checkout PR code
      uses: actions/checkout@v6
      with:
        ref: ${{ github.event.pull_request.head.sha }}

    - name: Cleanup Diskspace
      uses: kubeflow/pipelines/.github/actions/github-disk-cleanup@master
      if: (!cancelled())

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      with:
        driver-opts: network=host

    - name: Build component images from PR code
      run: |
        echo "======================================"
        echo "Building images from PR code..."
        echo "PR #${{ github.event.pull_request.number }}"
        echo "SHA: ${{ github.event.pull_request.head.sha }}"
        echo "======================================"

        docker build -t quay.io/ambient_code/vteam_frontend:claude-test \
          -f components/frontend/Dockerfile components/frontend
        
        docker build -t quay.io/ambient_code/vteam_backend:claude-test \
          -f components/backend/Dockerfile components/backend
        
        docker build -t quay.io/ambient_code/vteam_operator:claude-test \
          -f components/operator/Dockerfile components/operator
        
        docker build -t quay.io/ambient_code/vteam_claude_runner:claude-test \
          -f components/runners/claude-code-runner/Dockerfile components/runners

        echo "✅ All images built"

    - name: Install kind
      run: |
        curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
        chmod +x ./kind
        sudo mv ./kind /usr/local/bin/kind
        kind version

    - name: Setup kind cluster
      working-directory: e2e
      run: |
        chmod +x scripts/*.sh
        ./scripts/setup-kind.sh

    - name: Load images into kind cluster
      run: |
        echo "Loading images into kind cluster..."
        kind load docker-image quay.io/ambient_code/vteam_frontend:claude-test --name ambient-local
        kind load docker-image quay.io/ambient_code/vteam_backend:claude-test --name ambient-local
        kind load docker-image quay.io/ambient_code/vteam_operator:claude-test --name ambient-local
        kind load docker-image quay.io/ambient_code/vteam_claude_runner:claude-test --name ambient-local
        echo "✅ All images loaded"

    - name: Update kustomization to use claude-test images
      run: |
        sed -i 's/newTag: latest/newTag: claude-test/g' components/manifests/overlays/e2e/kustomization.yaml

    - name: Deploy vTeam
      working-directory: e2e
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      run: ./scripts/deploy.sh
        
    - name: Verify deployment
      run: |
        echo "Checking pods..."
        kubectl get pods -n ambient-code
        echo ""
        echo "Checking services..."
        kubectl get svc -n ambient-code

    - name: Get test token from kind
      id: token
      run: |
        TOKEN=$(kubectl get secret test-user-token -n ambient-code -o jsonpath='{.data.token}' | base64 -d)
        echo "token=$TOKEN" >> $GITHUB_OUTPUT
        echo "✅ Token retrieved from kind cluster"

  # Run Claude testing (works for both PR and manual modes)
  claude-test:
    name: Claude Live Testing
    runs-on: ubuntu-latest
    needs: [setup, deploy-to-kind]
    if: |
      needs.setup.outputs.should-run == 'true' &&
      (needs.setup.outputs.mode == 'manual' || needs.deploy-to-kind.result == 'success')
    timeout-minutes: 25
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Node.js
      uses: actions/setup-node@v6
      with:
        node-version: '20'

    - name: Install Playwright
      run: |
        npm install -g @playwright/mcp
        npx playwright install chromium
        echo "✅ Playwright installed"

    - name: Determine test configuration
      id: config
      run: |
        if [ "${{ needs.setup.outputs.mode }}" = "manual" ]; then
          BASE_URL="${{ needs.setup.outputs.base-url }}"
          TOKEN="${{ needs.setup.outputs.test-token }}"
          echo "Testing existing cluster at: $BASE_URL"
        else
          BASE_URL="http://localhost"
          TOKEN="${{ needs.deploy-to-kind.outputs.test-token }}"
          echo "Testing PR deployment in kind"
        fi
        
        echo "base-url=$BASE_URL" >> $GITHUB_OUTPUT
        echo "test-token=$TOKEN" >> $GITHUB_OUTPUT
        echo "✅ Configuration set"

    - name: Create MCP configuration for Playwright
      env:
        BASE_URL: ${{ steps.config.outputs.base-url }}
      run: |
        mkdir -p /tmp/mcp
        cat > /tmp/mcp/playwright-config.json << EOF
        {
          "mcpServers": {
            "playwright": {
              "command": "npx",
              "args": [
                "@playwright/mcp",
                "--base-url", "${BASE_URL}",
                "--output-dir", "/tmp/test_output",
                "--caps", "testing,pdf,tracing,vision",
                "--headless"
              ]
            }
          }
        }
        EOF
        echo "✅ MCP config created for ${BASE_URL}"
        cat /tmp/mcp/playwright-config.json

    - name: Create test prompt for Claude
      env:
        BASE_URL: ${{ steps.config.outputs.base-url }}
        TEST_TOKEN: ${{ steps.config.outputs.test-token }}
        TEST_PROMPT: ${{ needs.setup.outputs.test-prompt }}
        PR_NUMBER: ${{ github.event.pull_request.number }}
        PR_TITLE: ${{ github.event.pull_request.title }}
      run: |
        mkdir -p /tmp/test_output
        
        # Different prompts for PR vs manual testing
        if [ "${{ needs.setup.outputs.mode }}" = "manual" ]; then
          cat > /tmp/test-prompt.md << EOF
        # Manual Live Testing Task

        You are testing a deployed Ambient Code Platform instance.

        ## Application Access

        - **Frontend URL:** ${BASE_URL}
        - **Auth Token:** ${TEST_TOKEN}

        ## Testing Objective

        ${TEST_PROMPT}

        ## Your Mission

        1. **Navigate to the application** - Use browser_navigate
        2. **Explore the UI** - Use browser_snapshot to understand structure
        3. **Test functionality** - Create workspaces, sessions, test features
        4. **Document findings** - Create test report at /tmp/test_output/test_report.md

        ## Tips

        - Use browser tools to navigate, interact, and test
        - Use \`browser_snapshot()\` to understand page structure
        - Take screenshots at key test points
        - Be thorough but efficient (~20 minute budget)

        Begin testing now!
        EOF
        else
          cat > /tmp/test-prompt.md << EOF
        # PR Live Testing Task

        You are testing changes from PR #${PR_NUMBER}: "${PR_TITLE}"

        ## Application Access

        - **Frontend URL:** ${BASE_URL}
        - **Auth Token:** ${TEST_TOKEN}
        - **Test workspace:** claude-test-${GITHUB_RUN_ID}

        ## Your Mission

        1. **Navigate to the application**
        2. **Create test workspace:** claude-test-${GITHUB_RUN_ID}
        3. **Test the PR changes** - Focus on areas affected by this PR
        4. **Exploratory testing** - Try edge cases, test error handling
        5. **Generate test report** at /tmp/test_output/test_report.md with:
           - Executive summary
           - Test scenarios executed
           - Screenshots taken
           - Issues found (if any)
           - Overall assessment (✅ Pass / ⚠️ Issues / ❌ Fail)

        ## Tips

        - Use browser tools to navigate, interact, and test
        - Use \`browser_snapshot()\` to understand page structure
        - Take screenshots at key test points
        - Be thorough but efficient (~20 minute budget)

        Begin testing now!
        EOF
        fi
        
        echo "✅ Test prompt created"

    - name: Run Claude with Playwright MCP
      uses: anthropics/claude-code-action@v1
      env:
        TEST_TOKEN: ${{ steps.config.outputs.test-token }}
        BASE_URL: ${{ steps.config.outputs.base-url }}
      with:
        anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
        github_token: ${{ secrets.GITHUB_TOKEN }}
        prompt: |
          $(cat /tmp/test-prompt.md)
        claude_args: |
          --mcp-config /tmp/mcp/playwright-config.json
          --max-turns 30
          --model claude-sonnet-4-5-20250929

    - name: Upload test report and screenshots
      if: always()
      uses: actions/upload-artifact@v6
      with:
        name: claude-test-report-${{ github.run_id }}
        path: |
          /tmp/test_output/test_report.md
          /tmp/test_output/*.png
          /tmp/test_output/*.pdf
        if-no-files-found: ignore
        retention-days: 30

    - name: Upload Playwright traces (includes video)
      if: always()
      uses: actions/upload-artifact@v6
      with:
        name: playwright-traces-${{ github.run_id }}
        path: /tmp/test_output/traces
        if-no-files-found: ignore
        retention-days: 30
        
    - name: Debug logs on failure (kind only)
      if: failure() && needs.setup.outputs.mode == 'pr'
      run: |
        echo "=== Frontend logs ==="
        kubectl logs -n ambient-code -l app=frontend --tail=100 || true
        echo ""
        echo "=== Backend logs ==="
        kubectl logs -n ambient-code -l app=backend-api --tail=100 || true
        echo ""
        echo "=== Operator logs ==="
        kubectl logs -n ambient-code -l app=agentic-operator --tail=100 || true
        
    - name: Cleanup kind cluster
      if: always() && needs.setup.outputs.mode == 'pr'
      working-directory: e2e
      run: |
        CLEANUP_ARTIFACTS=true ./scripts/cleanup.sh || true
